{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in %s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Waiting for operation to complete...\n",
      "Transcript: 꿈에서요 거짓말 아니다 근데 내 모발이 딱 나오더니만 안아 보고 의자를 개새끼 군대 영장 받았습니다 다음에 입대하는 꿈\n",
      "Confidence: 0.8356379270553589\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "No matching overloads found for kr.lucypark.okt.OktInterface.tokenize(google.protobuf.pyext._message.RepeatedCompositeContainer,java.lang.Boolean,java.lang.Boolean), options are:\n\tpublic java.util.List kr.lucypark.okt.OktInterface.tokenize(java.lang.String,java.lang.Boolean,java.lang.Boolean)\n\n\tat JPMethod::findOverload(native\\common\\jp_method.cpp:242)\n\tat JPMethod::findOverload(native\\common\\jp_method.cpp:245)\n\tat JPMethod::invoke(native\\common\\jp_method.cpp:253)\n\tat PyJPMethod::__call__(native\\python\\pyjp_method.cpp:142)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-130fc2375a34>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Confidence: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malternative\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfidence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mword_info\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtwitter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malternative\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m         \u001b[0mwo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[0mword_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\konlpy\\tag\\_okt.py\u001b[0m in \u001b[0;36mpos\u001b[1;34m(self, phrase, norm, stem, join)\u001b[0m\n\u001b[0;32m     61\u001b[0m                     \u001b[0mphrase\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m                     \u001b[0mjpype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBoolean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                     jpype.java.lang.Boolean(stem)).toArray()\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mjoin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: No matching overloads found for kr.lucypark.okt.OktInterface.tokenize(google.protobuf.pyext._message.RepeatedCompositeContainer,java.lang.Boolean,java.lang.Boolean), options are:\n\tpublic java.util.List kr.lucypark.okt.OktInterface.tokenize(java.lang.String,java.lang.Boolean,java.lang.Boolean)\n\n\tat JPMethod::findOverload(native\\common\\jp_method.cpp:242)\n\tat JPMethod::findOverload(native\\common\\jp_method.cpp:245)\n\tat JPMethod::invoke(native\\common\\jp_method.cpp:253)\n\tat PyJPMethod::__call__(native\\python\\pyjp_method.cpp:142)\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import os\n",
    "from google.cloud import speech\n",
    "from google.cloud.speech import enums\n",
    "from google.cloud.speech import types\n",
    "import pandas as pd\n",
    "from konlpy.tag import Twitter\n",
    "from collections import Counter \n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import argparse\n",
    "from moviepy.editor import *\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import time\n",
    "import pyaudio\n",
    "import wave\n",
    "from array import array\n",
    "\n",
    "# 형태소 자르는것\n",
    "twitter = Twitter()\n",
    "\n",
    "xx = pd.read_csv(\"욕욕.csv\",names = [\"욕\"],encoding='cp949')\n",
    "vect = CountVectorizer(tokenizer=twitter.nouns)\n",
    "vect.fit(xx['욕']) # 욕사전 학습\n",
    "vect.vocabulary_ # 욕사전 확인\n",
    "\n",
    "#api json파일 설정\n",
    "GOOGLE_APPLICATION_CREDENTIALS = \"voice-be4b7165be4c.json\"\n",
    "\n",
    "# FORMAT=pyaudio.paInt16\n",
    "CHANNELS=2\n",
    "# RATE=44100\n",
    "# CHUNK=1024\n",
    "# RECORD_SECONDS=15\n",
    "# FILE_NAME=\"RECORDING.wav\"\n",
    "\n",
    "# audio=pyaudio.PyAudio() #instantiate the pyaudio\n",
    "\n",
    "# #recording prerequisites\n",
    "# stream=audio.open(format=FORMAT,channels=CHANNELS,\n",
    "#                   rate=RATE,\n",
    "#                   input=True,\n",
    "#                   frames_per_buffer=CHUNK)\n",
    "\n",
    "# #starting recording\n",
    "# frames=[]\n",
    "\n",
    "# for i in range(0,int(RATE/CHUNK*RECORD_SECONDS)):\n",
    "#     data=stream.read(CHUNK)\n",
    "#     data_chunk=array('h',data)\n",
    "#     vol=max(data_chunk)\n",
    "#     if(vol>=500):\n",
    "#         print(\"something said\")\n",
    "#         frames.append(data)\n",
    "#     else:\n",
    "#         print(\"nothing\")\n",
    "#     print(\"\\n\")\n",
    "\n",
    "\n",
    "# #end of recording\n",
    "# stream.stop_stream()\n",
    "# stream.close()\n",
    "# audio.terminate()\n",
    "# #writing to file\n",
    "# wavfile=wave.open(FILE_NAME,'wb')\n",
    "# wavfile.setnchannels(CHANNELS)\n",
    "# wavfile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "# wavfile.setframerate(RATE)\n",
    "# wavfile.writeframes(b''.join(frames))#append frames recorded to file\n",
    "\n",
    "\n",
    "client = speech.SpeechClient()\n",
    "videoclip = VideoFileClip(\"chulgoo4.mp4\")\n",
    "audioclip = videoclip.audio\n",
    "audioclip.to_audiofile('chulgoo4_음성.wav')\n",
    "wav_file = \"chulgoo4_음성.wav\"\n",
    "# wav_file = \"RECORDING.wav\"\n",
    "\n",
    "with io.open(wav_file, 'rb') as audio_file:\n",
    "    content = audio_file.read()            \n",
    "\n",
    "audio = types.RecognitionAudio(content=content)\n",
    "config = types.RecognitionConfig(\n",
    "    encoding=enums.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "    sample_rate_hertz=44100,audio_channel_count=CHANNELS,\n",
    "    language_code='ko-KR',\n",
    "    enable_word_time_offsets=True)\n",
    "\n",
    "operation = client.long_running_recognize(config, audio)\n",
    "\n",
    "\n",
    "print('Waiting for operation to complete...')\n",
    "result = operation.result(timeout=90)\n",
    "    \n",
    "word_list = []\n",
    "start_time_list = []\n",
    "end_time_list = []\n",
    "\n",
    "for k in result.results:\n",
    "    alternatives = k.alternatives\n",
    "    for alternative in alternatives:\n",
    "        print('Transcript: {}'.format(alternative.transcript))\n",
    "        print('Confidence: {}'.format(alternative.confidence))\n",
    "    \n",
    "    for word_info in alternative.words:\n",
    "        wo = word_info.word\n",
    "        word_list.append(wo)\n",
    "        start_time = word_info.start_time\n",
    "        end_time = word_info.end_time\n",
    "        start_time_list.append(start_time.seconds + start_time.nanos * 1e-9)\n",
    "        end_time_list.append(end_time.seconds + end_time.nanos * 1e-9)\n",
    "        print('Word: {}, start_time: {}, end_time: {}'.format(\n",
    "            wo,\n",
    "            start_time.seconds + start_time.nanos * 1e-9,\n",
    "            end_time.seconds + end_time.nanos * 1e-9))\n",
    "        \n",
    "sentences_tag = []\n",
    "for sentence in word_list:\n",
    "    morph = twitter.pos(sentence)\n",
    "    sentences_tag.append(morph)\n",
    "\n",
    "noun_adj_list = []\n",
    "for sentence1 in sentences_tag:\n",
    "    for word, tag in sentence1:\n",
    "        if tag in ['Noun','Adjective']:\n",
    "            noun_adj_list.append(word)\n",
    "\n",
    "word_vect = vect.transform(noun_adj_list)\n",
    "feature_list = []\n",
    "\n",
    "for i in word_vect.toarray():\n",
    "    for j in range(0,len(i)):\n",
    "        if i[j] == 1:\n",
    "            feature_list.append(vect.get_feature_names()[j])\n",
    "\n",
    "            \n",
    "sound1 = AudioSegment.from_file(wav_file)\n",
    "\n",
    "\n",
    "for i in range(0,len(word_list)):\n",
    "    for j in range(0,len(feature_list)):\n",
    "        if feature_list[j] in word_list[i]:\n",
    "            print(start_time_list[i])\n",
    "            print(end_time_list[i])\n",
    "            sound2 = AudioSegment.from_file(\"Beep2.wav\") \n",
    "            if end_time_list[i]-start_time_list[i]>2.5:\n",
    "                sound2 = sound2[start_time_list[i]*1000:(end_time_list[i]*1000)]\n",
    "                sound1 = sound1.overlay(sound2,position=(1000*start_time_list[i])+2500,gain_during_overlay =-100)\n",
    "            else :\n",
    "                sound2 = sound2[start_time_list[i]*1000:(end_time_list[i]*1000)]\n",
    "                sound1 = sound1.overlay(sound2,position=1000*start_time_list[i],gain_during_overlay =-100)\n",
    "            \n",
    "\n",
    "\n",
    "sound1.export(wav_file, format='wav')\n",
    "\n",
    "videoclip2 = videoclip.set_audio(AudioFileClip(wav_file))\n",
    "videoclip2.write_videofile('Chulgoo4_filter.avi',codec='libx264')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
